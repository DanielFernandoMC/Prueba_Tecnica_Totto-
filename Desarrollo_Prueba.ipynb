{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12nn_kR6TA548aFjkd_1t5B4RIRWurej8",
      "authorship_tag": "ABX9TyOMuaInbOmGSEmaG0mupVSy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielFernandoMC/Prueba_Tecnica_Totto-/blob/main/Desarrollo_Prueba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Se realiza el proceso ETL de los datos"
      ],
      "metadata": {
        "id": "BHubrQ90u64e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar archivos CSV con fechas parseadas\n",
        "ventas = pd.read_csv(\"ventas.csv\", parse_dates=[\"fecha_venta\"], sep=\",\" )\n",
        "clientes = pd.read_csv(\"clientes.csv\", parse_dates=[\"fecha_registro\"], sep=\",\")\n",
        "tiendas = pd.read_csv(\"tiendas.csv\", parse_dates=[\"fecha_apertura\"], sep=\",\")\n",
        "productos = pd.read_csv(\"productos.csv\", sep=\",\")\n",
        "\n",
        "# Normalizar nombres de columnas (snake_case)\n",
        "ventas.columns = ventas.columns.str.lower().str.strip().str.replace(\" \", \"_\")\n",
        "clientes.columns = clientes.columns.str.lower().str.strip().str.replace(\" \", \"_\")\n",
        "tiendas.columns = tiendas.columns.str.lower().str.strip().str.replace(\" \", \"_\")\n",
        "productos.columns = productos.columns.str.lower().str.strip().str.replace(\" \", \"_\")\n",
        "\n",
        "# Unificar tipos de ID como string\n",
        "ventas[\"id_cliente\"] = ventas[\"id_cliente\"].astype(str)\n",
        "ventas[\"id_producto\"] = ventas[\"id_producto\"].astype(str)\n",
        "ventas[\"id_tienda\"] = ventas[\"id_tienda\"].astype(str)\n",
        "clientes[\"id_cliente\"] = clientes[\"id_cliente\"].astype(str)\n",
        "productos[\"id_producto\"] = productos[\"id_producto\"].astype(str)\n",
        "tiendas[\"id_tienda\"] = tiendas[\"id_tienda\"].astype(str)\n",
        "\n",
        "# Añadir columnas derivadas a ventas\n",
        "ventas[\"año\"] = ventas[\"fecha_venta\"].dt.year\n",
        "ventas[\"mes\"] = ventas[\"fecha_venta\"].dt.month\n",
        "ventas[\"margen_unitario\"] = ventas[\"precio_unitario\"] - ventas[\"descuento\"]\n",
        "ventas[\"valor_total\"] = (ventas[\"precio_unitario\"] - ventas[\"descuento\"]) * ventas[\"cantidad\"]\n",
        "\n",
        "# Vista previa de los DF\n",
        "ventas.info()\n",
        "print(ventas.head())\n",
        "print()\n",
        "clientes.info()\n",
        "print(clientes.head())\n",
        "print()\n",
        "tiendas.info()\n",
        "print(tiendas.head())\n",
        "print()\n",
        "productos.info()\n",
        "print(productos.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "GuQ_Mi2vx3cK",
        "outputId": "1f1ba126-685d-4570-9b6d-6d86129d9a10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'ventas.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1622440662.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Cargar archivos CSV con fechas parseadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mventas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ventas.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fecha_venta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclientes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"clientes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fecha_registro\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtiendas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tiendas.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fecha_apertura\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ventas.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Análisis de datos"
      ],
      "metadata": {
        "id": "DmceOLVn6x2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a) Identificar los 5 productos más vendidos por tipo de tienda en el último trimestre (octubre - diciembre 2024), incluyendo el margen de ganancia promedio para cada producto."
      ],
      "metadata": {
        "id": "J743imgd-TpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fusionar ventas con productos y tiendas\n",
        "ventas_prod = ventas.merge(productos, on=\"id_producto\", how=\"left\")\n",
        "ventas_full = ventas_prod.merge(tiendas, on=\"id_tienda\", how=\"left\")\n",
        "\n",
        "# Filtrar último trimestre 2024\n",
        "ventas_q4 = ventas_full[\n",
        "    (ventas_full[\"fecha_venta\"] >= \"2024-10-01\") &\n",
        "    (ventas_full[\"fecha_venta\"] <= \"2024-12-31\")\n",
        "].copy()\n",
        "\n",
        "# Calcular margen real unitario\n",
        "ventas_q4[\"margen_unitario\"] = ventas_q4[\"precio_unitario\"] - ventas_q4[\"costo_unitario\"]\n",
        "\n",
        "# Agrupar por tipo tienda y producto\n",
        "agg = (\n",
        "    ventas_q4.groupby([\"tipo_tienda\", \"id_producto\", \"nombre_producto\"])\n",
        "    .agg(\n",
        "        cantidad_total=(\"cantidad\", \"sum\"),\n",
        "        margen_promedio=(\"margen_unitario\", \"mean\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Top 5 por tipo de tienda\n",
        "top5_por_tipo = agg.sort_values([\"tipo_tienda\", \"cantidad_total\"], ascending=[True, False])\n",
        "top5_final = top5_por_tipo.groupby(\"tipo_tienda\").head(5).reset_index(drop=True)\n",
        "print(top5_final)"
      ],
      "metadata": {
        "id": "s8nFNtHi0Hln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b) Desarrolle un análisis de cohorte mensual para evaluar la retención de clientes. Defina la cohorte como el mes de primera compra de cliente.\n"
      ],
      "metadata": {
        "id": "iJeOdyfH_hOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unir ventas con fecha de venta y cliente\n",
        "ventas_clientes = ventas.merge(clientes, on=\"id_cliente\", how=\"left\")\n",
        "\n",
        "# Obtener la fecha de primera compra (cohorte)\n",
        "ventas_clientes[\"cohorte\"] = ventas_clientes.groupby(\"id_cliente\")[\"fecha_venta\"].transform(\"min\")\n",
        "\n",
        "# Extraer año-mes\n",
        "ventas_clientes[\"cohorte_m\"] = ventas_clientes[\"cohorte\"].dt.to_period(\"M\")\n",
        "ventas_clientes[\"venta_m\"] = ventas_clientes[\"fecha_venta\"].dt.to_period(\"M\")\n",
        "\n",
        "# Calcular el índice de retención mensual\n",
        "cohort_data = ventas_clientes.groupby([\"cohorte_m\", \"venta_m\"])[\"id_cliente\"].nunique().reset_index()\n",
        "\n",
        "# Pivotear: cohorte como fila, mes de venta como columna\n",
        "cohort_pivot = cohort_data.pivot(index=\"cohorte_m\", columns=\"venta_m\", values=\"id_cliente\")\n",
        "\n",
        "# Normalizar por la primera columna (mes de adquisición)\n",
        "cohort_retention = cohort_pivot.divide(cohort_pivot.iloc[:, 0], axis=0).round(3)\n",
        "\n",
        "print(cohort_retention)\n"
      ],
      "metadata": {
        "id": "pI3eKDu9_kzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretación:\n",
        "\n",
        "Por ejemplo, para la cohorte de enero 2023:\n",
        "\n",
        "100% compró ese mes.\n",
        "\n",
        "96.4% compró en marzo 2023.\n",
        "\n",
        "~95–97% continuó comprando durante todo el periodo hasta diciembre 2024.\n",
        "\n",
        "Esto indica una retención bastante alta, lo cual es atípico si los datos fueran reales, y podría deberse a que se usaron datos simulados o replicados."
      ],
      "metadata": {
        "id": "SjLgm_3hAvgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c) Identifique ventas atípicas que podrían indicar errores de sistema o fraude. Utilice técnicas estadísticas (IQR, Z-score) o machine learning (Isolation Forest). Considere variables como cantidad, precio y comportamiento histórico.\n"
      ],
      "metadata": {
        "id": "FkZQ_r7jAxkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "\n",
        "# Selección de variables relevantes para detectar anomalías\n",
        "variables = ventas[[\"cantidad\", \"precio_unitario\", \"valor_total\"]].copy()\n",
        "\n",
        "# Reemplazar valores nulos si los hubiera (por ejemplo, por la mediana)\n",
        "variables = variables.fillna(variables.median(numeric_only=True))\n",
        "\n",
        "# -----------------------\n",
        "# MÉTODO 1: Z-score\n",
        "z_scores = (variables - variables.mean()) / variables.std()\n",
        "outliers_z = (np.abs(z_scores) > 3).any(axis=1)\n",
        "ventas[\"outlier_z\"] = outliers_z\n",
        "\n",
        "# -----------------------\n",
        "# MÉTODO 2: IQR\n",
        "Q1 = variables.quantile(0.25)\n",
        "Q3 = variables.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_iqr = ((variables < (Q1 - 1.5 * IQR)) | (variables > (Q3 + 1.5 * IQR))).any(axis=1)\n",
        "ventas[\"outlier_iqr\"] = outliers_iqr\n",
        "\n",
        "# -----------------------\n",
        "# MÉTODO 3: Isolation Forest\n",
        "modelo_iso = IsolationForest(contamination=0.01, random_state=42)\n",
        "ventas[\"outlier_iforest\"] = modelo_iso.fit_predict(variables) == -1\n",
        "\n",
        "# Consolidar resultados\n",
        "outliers_detectados = ventas[ventas[[\"outlier_z\", \"outlier_iqr\", \"outlier_iforest\"]].any(axis=1)]\n",
        "\n"
      ],
      "metadata": {
        "id": "7jXJyDpjXb85"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}